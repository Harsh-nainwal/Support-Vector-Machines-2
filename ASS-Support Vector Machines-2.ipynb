{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c93ab848-7922-470c-90eb-f8c48e301d44",
   "metadata": {},
   "source": [
    "Q1. What is the relationship between polynomial functions and kernel functions in machine learning\n",
    "algorithms?\n",
    "Ans;_\n",
    "Polynomial Functions:\n",
    "\n",
    "Polynomial functions are a type of mathematical function where the variable is raised to integer powers.\n",
    "In machine learning, polynomial functions are often used as basis functions for feature transformation. For example, in polynomial regression, the input features are transformed using polynomial functions to capture nonlinear relationships between the features and the target variable.\n",
    "Kernel Functions:\n",
    "\n",
    "Kernel functions are a way to implicitly compute the dot product between data points in a higher-dimensional space without explicitly transforming the data into that space.\n",
    "Polynomial kernel functions are a type of kernel function that compute the dot product between data points as if they were transformed into a higher-dimensional space using polynomial basis functions."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e7899bb-a5d3-41df-8f80-a8b0c801fac7",
   "metadata": {},
   "source": [
    "Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\n",
    "Ans:-\n",
    "we can implement an SVM with a polynomial kernel in Python using Scikit-learn by utilizing the SVC (Support Vector Classifier) class and specifying the kernel parameter as 'poly'.\n",
    "svm_classifier = SVC(kernel='poly')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29a596dd-377e-478f-8534-c8eeffe42fc2",
   "metadata": {},
   "source": [
    "Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
    "Ans:-\n",
    " Support Vector Regression (SVR), epsilon is a hyperparameter that defines the margin of tolerance where no penalty is given to errors that are within this margin. It is part of the formulation of the SVR loss function and affects the number of support vectors \n",
    "When you increase the value of epsilon, you are expanding the margin of tolerance for errors.\n",
    "This means that the SVR model allows more training points to be within the margin of tolerance and still be considered correctly predicted."
   ]
  },
  {
   "cell_type": "raw",
   "id": "02ea4a0c-dc48-4b86-88a1-cd1ca76ac9eb",
   "metadata": {},
   "source": [
    "Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter\n",
    "affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works\n",
    "and provide examples of when you might want to increase or decrease its value?\n",
    "\n",
    "Kernel Function:\n",
    "\n",
    "Choice of kernel function affects how SVR models non-linear relationships in the data.\n",
    "Common kernels include linear, polynomial, radial basis function (RBF), and sigmoid.\n",
    "For complex, non-linear relationships, RBF kernel is often effective. Linear kernel is suitable for linear relationships.\n",
    "Example: If the relationship between features and target is highly non-linear, using an RBF kernel might be beneficial.\n",
    "\n",
    "\n",
    "C Parameter:\n",
    "\n",
    "C parameter controls the trade-off between maximizing the margin and minimizing the training error.\n",
    "Larger C values penalize errors more heavily, potentially leading to overfitting.\n",
    "Smaller C values allow more errors within the margin, potentially improving generalization.\n",
    "Example: If you have noisy data, you might decrease C to make the model more tolerant to errors.\n",
    "\n",
    "Epsilon Parameter:\n",
    "\n",
    "Epsilon parameter determines the margin of tolerance around the predicted value.\n",
    "It specifies the width of the epsilon-insensitive tube where no penalty is associated with errors.\n",
    "Increasing epsilon can lead to a wider margin and a simpler model.\n",
    "Gamma Parameter:\n",
    "\n",
    "Gamma parameter defines how far the influence of a single training example reaches.\n",
    "Higher gamma values lead to closer data points having higher weights, resulting in a more complex decision boundary.\n",
    "Lower gamma values give points further away from the decision boundary influence, leading to smoother decision boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f92ebc4-4843-4531-8cd6-142e6a88d139",
   "metadata": {},
   "source": [
    "Q5. Assignment:\n",
    "L Import the necessary libraries and load the dataseg\n",
    "L Split the dataset into training and testing setZ\n",
    "L Preprocess the data using any technique of your choice (e.g. scaling, normaliMationK\n",
    "L Create an instance of the SVC classifier and train it on the training datW\n",
    "L hse the trained classifier to predict the labels of the testing datW\n",
    "L Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\n",
    "precision, recall, F1-scoreK\n",
    "L Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to\n",
    "improve its performanc_\n",
    "L Train the tuned classifier on the entire dataseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e9d1b5-db84-4808-bfd0-6562a358f801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Best parameters: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=100, gamma=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100, gamma=0.01)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=100, gamma=0.01)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#to scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm_classifier = SVC()\n",
    "\n",
    "svm_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "y_pred = svm_classifier.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# hyperparameters using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['rbf', 'linear', 'poly', 'sigmoid']}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Train the tuned classifier on the entire dataset\n",
    "tuned_clf = grid_search.best_estimator_\n",
    "tuned_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# saving for future use\n",
    "\n",
    "import pickle\n",
    "filename = 'svm_classifier_model.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(tuned_classifier, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb2d094-4188-4887-836c-8c896798d001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
